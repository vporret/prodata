{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20  4  6]\n",
      " [ 4 16  2]\n",
      " [12  2 32]]\n",
      "\n",
      "True positive 0 =  20.41 %\n",
      "False positive 0 =  16.33 %\n",
      "True negative 0  =  53.06 %\n",
      "False negative 0 =  10.2 %\n",
      "\n",
      "True positive 1 =  16.33 %\n",
      "False positive 1 =  6.12 %\n",
      "True negative 1 =  71.43 %\n",
      "False negative 1 =  6.12 %\n",
      "\n",
      "True positive 2 =  32.65 %\n",
      "False positive 2 =  8.16 %\n",
      "True negative 2 =  44.9 %\n",
      "False negative 2 =  14.29 %\n",
      "\n",
      "Micro-Averaged Precision =  0.6939\n",
      "Macro-Averaged Recall =  0.6943\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix,precision_score\n",
    "\n",
    "\n",
    "y_true = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,\\\n",
    "          2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,\\\n",
    "          1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2]\n",
    "y_pred = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,\\\n",
    "          2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,2,2,2,2,2,2,\\\n",
    "          0,0,0,0,2,2,0,0,0,0,0,0,0,0,0,0,0,0,1,1]\n",
    "\n",
    "\n",
    "cm =confusion_matrix(y_true, y_pred, labels=[0,1,2])\n",
    "\n",
    "print(cm)\n",
    "\n",
    "tp0 = cm[0][0]\n",
    "fp0 = cm[1][0]+cm[2][0]\n",
    "tn0 = cm[1][1]+cm[1][2]+cm[2][1]+cm[2][2]\n",
    "fn0 = cm[0][1]+cm[0][2]\n",
    "total = sum(sum(cm))\n",
    "\n",
    "\n",
    "\n",
    "print('\\nTrue positive 0 = ', round(tp0/total*100,2),\"%\")\n",
    "print('False positive 0 = ', round(fp0/total*100,2),\"%\")\n",
    "print('True negative 0  = ', round(tn0/total*100,2),\"%\")\n",
    "print('False negative 0 = ', round(fn0/total*100,2),\"%\")\n",
    "\n",
    "tp1 = cm[1][1]\n",
    "fp1 = cm[0][1]+cm[2][1]\n",
    "tn1 = cm[0][0]+cm[0][2]+cm[2][0]+cm[2][2]\n",
    "fn1 = cm[1][0]+cm[1][2]\n",
    "\n",
    "\n",
    "print('\\nTrue positive 1 = ', round(tp1/total*100,2),\"%\")\n",
    "print('False positive 1 = ', round(fp1/total*100,2),\"%\")\n",
    "print('True negative 1 = ', round(tn1/total*100,2),\"%\")\n",
    "print('False negative 1 = ', round(fn1/total*100,2),\"%\")\n",
    "\n",
    "tp2 = cm[2][2]\n",
    "fp2 = cm[0][2]+cm[1][2]\n",
    "tn2 = cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1]\n",
    "fn2 = cm[2][0]+cm[2][1]\n",
    "\n",
    "\n",
    "print('\\nTrue positive 2 = ', round(tp2/total*100,2),\"%\")\n",
    "print('False positive 2 = ', round(fp2/total*100,2),\"%\")\n",
    "print('True negative 2 = ', round(tn2/total*100,2),\"%\")\n",
    "print('False negative 2 = ', round(fn2/total*100,2),\"%\")\n",
    "\n",
    "MAP = (tp0+tp1+tp2)/(tp0+tp1+tp2+fp0+fp1+fp2)\n",
    "MAR = ((tp0/(fp0+tp0))+(tp1/(fp1+tp1))+(tp2/(fp2+tp2)))/3\n",
    "\n",
    "\n",
    "print(\"\\nMicro-Averaged Precision = \", round(MAP,4))\n",
    "print(\"Macro-Averaged Recall = \", round(MAR,4))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
